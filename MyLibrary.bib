
@article{mcsherry_mechanism_nodate,
	title = {Mechanism {Design} via {Differential} {Privacy}},
	abstract = {We study the role that privacy-preserving algorithms, which prevent the leakage of speciﬁc information about participants, can play in the design of mechanisms for strategic agents, which must encourage players to honestly report information. Speciﬁcally, we show that the recent notion of differential privacy [15, 14], in addition to its own intrinsic virtue, can ensure that participants have limited effect on the outcome of the mechanism, and as a consequence have limited incentive to lie. More precisely, mechanisms with differential privacy are approximate dominant strategy under arbitrary player utility functions, are automatically resilient to coalitions, and easily allow repeatability.},
	%%language = {en},
	author = {McSherry, Frank and Talwar, Kunal},
	pages = {10},
	file = {McSherry and Talwar - Mechanism Design via Differential Privacy.pdf:C\:\\Users\\ituki\\Zotero\\storage\\J7CEECM6\\McSherry and Talwar - Mechanism Design via Differential Privacy.pdf:application/pdf},
}

@article{beimel_characterizing_nodate,
	title = {Characterizing the {Sample} {Complexity} of {Pure} {Private} {Learners}},
	abstract = {Kasiviswanathan et al. (FOCS 2008) deﬁned private learning as a combination of PAC learning and diﬀerential privacy. Informally, a private learner is applied to a collection of labeled individual information and outputs a hypothesis while preserving the privacy of each individual. Kasiviswanathan et al. left open the question of characterizing the sample complexity of private learners.},
	%language = {en},
	author = {Beimel, Amos and Nissim, Kobbi and Stemmer, Uri},
	pages = {33},
	file = {Beimel et al. - Characterizing the Sample Complexity of Pure Priva.pdf:C\:\\Users\\ituki\\Zotero\\storage\\VR6TBUTQ\\Beimel et al. - Characterizing the Sample Complexity of Pure Priva.pdf:application/pdf},
}

@article{letham_constrained_2019,
	title = {Constrained {Bayesian} {Optimization} with {Noisy} {Experiments}},
	volume = {14},
	issn = {1936-0975, 1931-6690},
	url = {https://projecteuclid.org/euclid.ba/1533866666},
	doi = {10.1214/18-BA1110},
	abstract = {Randomized experiments are the gold standard for evaluating the effects of changes to real-world systems. Data in these tests may be difficult to collect and outcomes may have high variance, resulting in potentially large measurement error. Bayesian optimization is a promising technique for efficiently optimizing multiple continuous parameters, but existing approaches degrade in performance when the noise level is high, limiting its applicability to many randomized experiments. We derive an expression for expected improvement under greedy batch optimization with noisy observations and noisy constraints, and develop a quasi-Monte Carlo approximation that allows it to be efficiently optimized. Simulations with synthetic functions show that optimization performance on noisy, constrained problems outperforms existing methods. We further demonstrate the effectiveness of the method with two real-world experiments conducted at Facebook: optimizing a ranking system, and optimizing server compiler flags.},
	%%language = {EN},
	number = {2},
	%%%%%urldate = {2021-02-02},
	journal = {Bayesian Analysis},
	author = {Letham, Benjamin and Karrer, Brian and Ottoni, Guilherme and Bakshy, Eytan},
	month = jun,
	year = {2019},
	mrnumber = {MR3934095},
	zmnumber = {07045440},
	note = {Publisher: International Society for Bayesian Analysis},
	keywords = {Bayesian optimization, quasi-Monte Carlo methods, randomized experiments},
	pages = {495--519},
	file = {Full Text PDF:C\:\\Users\\ituki\\Zotero\\storage\\E2BBZ4KI\\Letham et al. - 2019 - Constrained Bayesian Optimization with Noisy Exper.pdf:application/pdf;Snapshot:C\:\\Users\\ituki\\Zotero\\storage\\YFU8CMS3\\1533866666.html:text/html;Full Text PDF:C\:\\Users\\ituki\\Zotero\\storage\\2YBT836L\\Letham et al. - 2019 - Constrained Bayesian Optimization with Noisy Exper.pdf:application/pdf;Snapshot:C\:\\Users\\ituki\\Zotero\\storage\\9378EI4U\\1533866666.html:text/html},
}

@book{rasmussen_gaussian_2006,
	address = {Cambridge, Mass},
	series = {Adaptive computation and machine learning},
	title = {Gaussian processes for machine learning},
	isbn = {978-0-262-18253-9},
	%%language = {en},
	publisher = {MIT Press},
	author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
	year = {2006},
	note = {OCLC: ocm61285753},
	keywords = {Data processing, Gaussian processes, Machine learning, Mathematical models},
	file = {Rasmussen and Williams - 2006 - Gaussian processes for machine learning.pdf:C\:\\Users\\ituki\\Zotero\\storage\\W2IXZKWC\\Rasmussen and Williams - 2006 - Gaussian processes for machine learning.pdf:application/pdf},
}

@article{kandasamy_multi-fidelity_2019,
	title = {Multi-fidelity {Gaussian} {Process} {Bandit} {Optimisation}},
	volume = {66},
	copyright = {Copyright (c)},
	issn = {1076-9757},
	url = {https://jair.org/index.php/jair/article/view/11288},
	doi = {10.1613/jair.1.11288},
	%%language = {en},
	%%%%%urldate = {2021-02-02},
	journal = {Journal of Artificial Intelligence Research},
	author = {Kandasamy, Kirthevasan and Dasarathy, Gautam and Oliva, Junier and Schneider, Jeff and Póczos, Barnabás},
	month = sep,
	year = {2019},
	keywords = {Bayesian optimization, bandits, machine learning},
	pages = {151--196},
	file = {Full Text PDF:C\:\\Users\\ituki\\Zotero\\storage\\VTC8KIM8\\Kandasamy et al. - 2019 - Multi-fidelity Gaussian Process Bandit Optimisatio.pdf:application/pdf;Snapshot:C\:\\Users\\ituki\\Zotero\\storage\\6SKLPMBX\\11288.html:text/html},
}

@article{andrew_new_nodate,
	title = {New {Techniques} in {Deep} {Representation} {Learning}},
	%%language = {en},
	author = {Andrew, Galen},
	pages = {131},
	file = {Andrew - New Techniques in Deep Representation Learning.pdf:C\:\\Users\\ituki\\Zotero\\storage\\QMG9FPKF\\Andrew - New Techniques in Deep Representation Learning.pdf:application/pdf},
}

@inproceedings{chai_generalization_2009,
	title = {Generalization {Errors} and {Learning} {Curves} for {Regression} with {Multi}-task {Gaussian} {Processes}},
	url = {https://openreview.net/forum?id=FYEhSj1PwQKs},
	abstract = {We provide some insights into how task correlations in multi-task Gaussian process (GP) regression affect the generalization error and the learning curve. We analyze the asymmetric two-task case...},
	%%language = {en},
	%%%%%urldate = {2021-02-05},
	author = {Chai, Kian Ming Adam},
	month = jan,
	year = {2009},
	file = {Snapshot:C\:\\Users\\ituki\\Zotero\\storage\\SJ4TEUVL\\forum.html:text/html},
}

@article{beimel_bounds_2014,
	title = {Bounds on the sample complexity for private learning and private data release},
	volume = {94},
	issn = {1573-0565},
	url = {https://doi.org/10.1007/s10994-013-5404-1},
	doi = {10.1007/s10994-013-5404-1},
	abstract = {Learning is a task that generalizes many of the analyses that are applied to collections of data, in particular, to collections of sensitive individual information. Hence, it is natural to ask what can be learned while preserving individual privacy. Kasiviswanathan et al. (in SIAM J. Comput., 40(3):793–826, 2011) initiated such a discussion. They formalized the notion of private learning, as a combination of PAC learning and differential privacy, and investigated what concept classes can be learned privately. Somewhat surprisingly, they showed that for finite, discrete domains (ignoring time complexity), every PAC learning task could be performed privately with polynomially many labeled examples; in many natural cases this could even be done in polynomial time.},
	%%language = {en},
	number = {3},
	%%%%%urldate = {2021-02-07},
	journal = {Machine Learning},
	author = {Beimel, Amos and Brenner, Hai and Kasiviswanathan, Shiva Prasad and Nissim, Kobbi},
	month = mar,
	year = {2014},
	pages = {401--437},
	file = {Springer Full Text PDF:C\:\\Users\\ituki\\Zotero\\storage\\25H8EHWR\\Beimel et al. - 2014 - Bounds on the sample complexity for private learni.pdf:application/pdf},
}

@article{noauthor_notitle_nodate,
}

@article{dwork_calibrating_nodate,
	title = {Calibrating {Noise} to {Sensitivity} in {Private} {Data} {Analysis}},
	abstract = {We continue a line of research initiated in [10, 11] on privacypreserving statistical databases. Consider a trusted server that holds a database of sensitive information. Given a query function f mapping databases to reals, the so-called true answer is the result of applying f to the database. To protect privacy, the true answer is perturbed by the addition of random noise generated according to a carefully chosen distribution, and this response, the true answer plus noise, is returned to the user.},
	%%language = {en},
	author = {Dwork, Cynthia and McSherry, Frank and Nissim, Kobbi and Smith, Adam},
	pages = {20},
	file = {Dwork et al. - Calibrating Noise to Sensitivity in Private Data A.pdf:C\:\\Users\\ituki\\Zotero\\storage\\F2MUKH6Y\\Dwork et al. - Calibrating Noise to Sensitivity in Private Data A.pdf:application/pdf},
}

@incollection{reingold_differential_2009,
	address = {Berlin, Heidelberg},
	title = {The {Differential} {Privacy} {Frontier} ({Extended} {Abstract})},
	volume = {5444},
	isbn = {978-3-642-00456-8 978-3-642-00457-5},
	url = {http://link.springer.com/10.1007/978-3-642-00457-5_29},
	abstract = {We review the deﬁnition of diﬀerential privacy and brieﬂy survey a handful of very recent contributions to the diﬀerential privacy frontier.},
	%%language = {en},
	%%%%%urldate = {2021-02-07},
	booktitle = {Theory of {Cryptography}},
	publisher = {Springer Berlin Heidelberg},
	author = {Dwork, Cynthia},
	editor = {Reingold, Omer},
	year = {2009},
	doi = {10.1007/978-3-642-00457-5_29},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {496--502},
	file = {Dwork - 2009 - The Differential Privacy Frontier (Extended Abstra.pdf:C\:\\Users\\ituki\\Zotero\\storage\\F7VA7HVD\\Dwork - 2009 - The Differential Privacy Frontier (Extended Abstra.pdf:application/pdf},
}

@article{vapnik_translated_nodate,
	title = {({Translated} by {B}. {Seckler})},
	%%language = {en},
	author = {Vapnik, V N and Chervonenkis, A Ya},
	pages = {17},
	file = {Vapnik and Chervonenkis - (Translated by B. Seckler).pdf:C\:\\Users\\ituki\\Zotero\\storage\\BNHNQLMP\\Vapnik and Chervonenkis - (Translated by B. Seckler).pdf:application/pdf},
}

@inproceedings{bun_differentially_2015,
	address = {Berkeley, CA, USA},
	title = {Differentially {Private} {Release} and {Learning} of {Threshold} {Functions}},
	isbn = {978-1-4673-8191-8},
	url = {http://ieeexplore.ieee.org/document/7354419/},
	doi = {10.1109/FOCS.2015.45},
	abstract = {We prove new upper and lower bounds on the sample complexity of (ε, δ) diﬀerentially private algorithms for releasing approximate answers to threshold functions. A threshold function cx over a totally ordered domain X evaluates to cx(y) = 1 if y ≤ x, and evaluates to 0 otherwise. We give the ﬁrst nontrivial lower bound for releasing thresholds with (ε, δ) diﬀerential privacy, showing that the task is impossible over an inﬁnite domain X, and moreover requires sample complexity n ≥ Ω(log∗ {\textbar}X{\textbar}), which grows with the size of the domain. Inspired by the techniques used to prove this lower bound, we give an algorithm for releasing thresholds with n ≤ 2(1+o(1)) log∗ {\textbar}X{\textbar} samples. This improves the previous best upper bound of 8(1+o(1)) log∗ {\textbar}X{\textbar} (Beimel et al., RANDOM ’13).},
	%%language = {en},
	%%%%%urldate = {2021-02-07},
	booktitle = {2015 {IEEE} 56th {Annual} {Symposium} on {Foundations} of {Computer} {Science}},
	publisher = {IEEE},
	author = {Bun, Mark and Nissim, Kobbi and Stemmer, Uri and Vadhan, Salil},
	month = oct,
	year = {2015},
	pages = {634--649},
	file = {Bun et al. - 2015 - Differentially Private Release and Learning of Thr.pdf:C\:\\Users\\ituki\\Zotero\\storage\\VTPVSU32\\Bun et al. - 2015 - Differentially Private Release and Learning of Thr.pdf:application/pdf},
}

@article{kasiviswanathan_what_2010,
	title = {What {Can} {We} {Learn} {Privately}?},
	url = {http://arxiv.org/abs/0803.0924},
	abstract = {Learning problems form an important category of computational tasks that generalizes many of the computations researchers apply to large real-life data sets. We ask: what concept classes can be learned privately, namely, by an algorithm whose output does not depend too heavily on any one input or speciﬁc training example? More precisely, we investigate learning algorithms that satisfy differential privacy, a notion that provides strong conﬁdentiality guarantees in contexts where aggregate information is released about a database containing sensitive information about individuals.},
	%%language = {en},
	%%%%%urldate = {2021-02-07},
	journal = {arXiv:0803.0924 [cs]},
	author = {Kasiviswanathan, Shiva Prasad and Lee, Homin K. and Nissim, Kobbi and Raskhodnikova, Sofya and Smith, Adam},
	month = feb,
	year = {2010},
	note = {arXiv: 0803.0924},
	keywords = {Computer Science - Computational Complexity, Computer Science - Cryptography and Security, Computer Science - Databases, Computer Science - Machine Learning},
	file = {Kasiviswanathan et al. - 2010 - What Can We Learn Privately.pdf:C\:\\Users\\ituki\\Zotero\\storage\\24UU6RTH\\Kasiviswanathan et al. - 2010 - What Can We Learn Privately.pdf:application/pdf},
}

@article{mitchell_spatial_nodate,
	title = {The {Spatial} {Inductive} {Bias} of {Deep} {Learning}},
	%%language = {en},
	author = {Mitchell, Benjamin R},
	pages = {254},
	file = {Mitchell - The Spatial Inductive Bias of Deep Learning.pdf:C\:\\Users\\ituki\\Zotero\\storage\\WB47YLDH\\Mitchell - The Spatial Inductive Bias of Deep Learning.pdf:application/pdf},
}

@inproceedings{kearns_introduction_1994,
	title = {An {Introduction} to {Computational} {Learning} {Theory}},
	doi = {10.7551/mitpress/3897.001.0001},
	abstract = {The probably approximately correct learning model Occam's razor the Vapnik-Chervonenkis dimension weak and strong learning learning in the presence of noise inherent unpredictability reducibility in PAC learning learning finite automata by experimentation appendix - some tools for probabilistic analysis.},
	author = {Kearns, M. and Vazirani, U.},
	year = {1994},
	file = {Full Text PDF:C\:\\Users\\ituki\\Zotero\\storage\\NWRPAASH\\Kearns and Vazirani - 1994 - An Introduction to Computational Learning Theory.pdf:application/pdf},
}

@incollection{hutchison_private_2013,
	address = {Berlin, Heidelberg},
	title = {Private {Learning} and {Sanitization}: {Pure} vs. {Approximate} {Differential} {Privacy}},
	volume = {8096},
	isbn = {978-3-642-40327-9 978-3-642-40328-6},
	shorttitle = {Private {Learning} and {Sanitization}},
	url = {http://link.springer.com/10.1007/978-3-642-40328-6_26},
	abstract = {We compare the sample complexity of private learning and sanitization tasks under pure -diﬀerential privacy [Dwork, McSherry, Nissim, and Smith TCC 2006] and approximate ( , δ)-diﬀerential privacy [Dwork, Kenthapadi, McSherry, Mironov, and Naor EUROCRYPT 2006]. We show that the sample complexity of these tasks under approximate diﬀerential privacy can be signiﬁcantly lower than that under pure diﬀerential privacy.},
	%%language = {en},
	%%%%%urldate = {2021-02-08},
	booktitle = {Approximation, {Randomization}, and {Combinatorial} {Optimization}. {Algorithms} and {Techniques}},
	publisher = {Springer Berlin Heidelberg},
	author = {Beimel, Amos and Nissim, Kobbi and Stemmer, Uri},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Raghavendra, Prasad and Raskhodnikova, Sofya and Jansen, Klaus and Rolim, José D. P.},
	year = {2013},
	doi = {10.1007/978-3-642-40328-6_26},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {363--378},
	file = {Beimel et al. - 2013 - Private Learning and Sanitization Pure vs. Approx.pdf:C\:\\Users\\ituki\\Zotero\\storage\\WCFXEJ7Y\\Beimel et al. - 2013 - Private Learning and Sanitization Pure vs. Approx.pdf:application/pdf},
}

@article{tenenbaum_global_2000,
	title = {A {Global} {Geometric} {Framework} for {Nonlinear} {Dimensionality} {Reduction}},
	volume = {290},
	issn = {0036-8075, 1095-9203},
	url = {https://science.sciencemag.org/content/290/5500/2319},
	doi = {10.1126/science.290.5500.2319},
	abstract = {Scientists working with large volumes of high-dimensional data, such as global climate patterns, stellar spectra, or human gene distributions, regularly confront the problem of dimensionality reduction: finding meaningful low-dimensional structures hidden in their high-dimensional observations. The human brain confronts the same problem in everyday perception, extracting from its high-dimensional sensory inputs—30,000 auditory nerve fibers or 106 optic nerve fibers—a manageably small number of perceptually relevant features. Here we describe an approach to solving dimensionality reduction problems that uses easily measured local metric information to learn the underlying global geometry of a data set. Unlike classical techniques such as principal component analysis (PCA) and multidimensional scaling (MDS), our approach is capable of discovering the nonlinear degrees of freedom that underlie complex natural observations, such as human handwriting or images of a face under different viewing conditions. In contrast to previous algorithms for nonlinear dimensionality reduction, ours efficiently computes a globally optimal solution, and, for an important class of data manifolds, is guaranteed to converge asymptotically to the true structure.},
	%%language = {en},
	number = {5500},
	%%%%%urldate = {2021-02-09},
	journal = {Science},
	author = {Tenenbaum, Joshua B. and Silva, Vin de and Langford, John C.},
	month = dec,
	year = {2000},
	pmid = {11125149},
	note = {Publisher: American Association for the Advancement of Science
Section: Report},
	pages = {2319--2323},
	file = {Snapshot:C\:\\Users\\ituki\\Zotero\\storage\\4NCUPH3T\\2319.html:text/html},
}

@misc{noauthor_global_nodate,
	title = {A {Global} {Geometric} {Framework} for {Nonlinear} {Dimensionality} {Reduction} {\textbar} {Science}},
	url = {https://science.sciencemag.org/content/290/5500/2319.abstract},
	%%%%%urldate = {2021-02-09},
}

@article{bahdanau_neural_2016,
	title = {Neural {Machine} {Translation} by {Jointly} {Learning} to {Align} and {Translate}},
	url = {http://arxiv.org/abs/1409.0473},
	abstract = {Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.},
	%%%%%urldate = {2021-02-11},
	journal = {arXiv:1409.0473 [cs, stat]},
	author = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
	month = may,
	year = {2016},
	note = {arXiv: 1409.0473},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\ituki\\Zotero\\storage\\LM5HNJM4\\Bahdanau et al. - 2016 - Neural Machine Translation by Jointly Learning to .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\ituki\\Zotero\\storage\\YJFGZLCH\\1409.html:text/html},
}

@inproceedings{ngiam_multimodal_2011,
	title = {Multimodal {Deep} {Learning}},
	abstract = {Deep networks have been successfully applied to unsupervised feature learning for single modalities (e.g., text, images or audio). In this work, we propose a novel application of deep networks to learn features over multiple modalities. We present a series of tasks for multimodal learning and show how to train deep networks that learn features to address these tasks. In particular, we demonstrate cross modality feature learning, where better features for one modality (e.g., video) can be learned if multiple modalities (e.g., audio and video) are present at feature learning time. Furthermore, we show how to learn a shared representation between modalities and evaluate it on a unique task, where the classifier is trained with audio-only data but tested with video-only data and vice-versa. Our models are validated on the CUAVE and AVLetters datasets on audio-visual speech classification, demonstrating best published visual speech classification on AVLetters and effective shared representation learning. 1.},
	author = {Ngiam, Jiquan and Khosla, Aditya and Kim, Mingyu and Nam, Juhan and Lee, Honglak and Ng, Andrew},
	month = jan,
	year = {2011},
	pages = {689--696},
	file = {Full Text PDF:C\:\\Users\\ituki\\Zotero\\storage\\C6ZHFZ8M\\Ngiam et al. - 2011 - Multimodal Deep Learning.pdf:application/pdf;Full Text PDF:C\:\\Users\\ituki\\Zotero\\storage\\CFDY7R4W\\Ngiam et al. - 2011 - Multimodal Deep Learning.pdf:application/pdf},
}

@article{lafferty_conditional_nodate,
	title = {Conditional {Random} {Fields}: {Probabilistic} {Models} for {Segmenting} and {Labeling} {Sequence} {Data}},
	abstract = {We present conditional random fields, a framework for building probabilistic models to segment and label sequence data. Conditional random fields offer several advantages over hidden Markov models and stochastic grammars for such tasks, including the ability to relax strong independence assumptions made in those models. Conditional random fields also avoid a fundamental limitation of maximum entropy Markov models (MEMMs) and other discriminative Markov models based on directed graphical models, which can be biased towards states with few successor states. We present iterative parameter estimation algorithms for conditional random fields and compare the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data.},
	%%language = {en},
	author = {Lafferty, John and McCallum, Andrew and Pereira, Fernando C N},
	pages = {10},
	file = {Lafferty et al. - Conditional Random Fields Probabilistic Models fo.pdf:C\:\\Users\\ituki\\Zotero\\storage\\KWE7T5EC\\Lafferty et al. - Conditional Random Fields Probabilistic Models fo.pdf:application/pdf},
}

@article{dai_smooth_nodate,
	title = {Smooth neighborhood recommender systems},
	abstract = {Recommender systems predict users’ preferences over a large number of items by pooling similar information from other users and/or items in the presence of sparse observations. One major challenge is how to utilize user-item speciﬁc covariates and networks describing user-item interactions in a high-dimensional situation, for accurate personalized prediction. In this article, we propose a smooth neighborhood recommender in the framework of the latent factor models. A similarity kernel is utilized to borrow neighborhood information from continuous covariates over a user-item speciﬁc network, such as a user’s social network, where the grouping information deﬁned by discrete covariates is also integrated through the network. Consequently, user-item speciﬁc information is built into the recommender to battle the ‘cold-start” issue in the absence of observations in collaborative and contentbased ﬁltering. Moreover, we utilize a “divide-and-conquer” version of the alternating least squares algorithm to achieve scalable computation, and establish asymptotic results for the proposed method, demonstrating that it achieves superior prediction accuracy. Finally, we illustrate that the proposed method improves substantially over its competitors in simulated examples and real benchmark data–Last.fm music data.},
	%%language = {en},
	author = {Dai, Ben and Wang, Junhui and Shen, Xiaotong and Qu, Annie},
	pages = {24},
	file = {Dai et al. - Smooth neighborhood recommender systems.pdf:C\:\\Users\\ituki\\Zotero\\storage\\TIRC55RM\\Dai et al. - Smooth neighborhood recommender systems.pdf:application/pdf},
}

@article{goodfellow_generative_2014,
	title = {Generative {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1406.2661},
	abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
	%%%%%urldate = {2021-02-17},
	journal = {arXiv:1406.2661 [cs, stat]},
	author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	month = jun,
	year = {2014},
	note = {arXiv: 1406.2661},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\ituki\\Zotero\\storage\\I8WNNMHW\\Goodfellow et al. - 2014 - Generative Adversarial Networks.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\ituki\\Zotero\\storage\\IJ32A4PA\\1406.html:text/html},
}

@article{andoni_practical_2015,
	title = {Practical and {Optimal} {LSH} for {Angular} {Distance}},
	url = {http://arxiv.org/abs/1509.02897},
	abstract = {We show the existence of a Locality-Sensitive Hashing (LSH) family for the angular distance that yields an approximate Near Neighbor Search algorithm with the asymptotically optimal running time exponent. Unlike earlier algorithms with this property (e.g., Spherical LSH [1, 2]), our algorithm is also practical, improving upon the well-studied hyperplane LSH [3] in practice. We also introduce a multiprobe version of this algorithm, and conduct experimental evaluation on real and synthetic data sets. We complement the above positive results with a ﬁne-grained lower bound for the quality of any LSH family for angular distance. Our lower bound implies that the above LSH family exhibits a trade-oﬀ between evaluation time and quality that is close to optimal for a natural class of LSH functions.},
	%%language = {en},
	%%%%%urldate = {2021-02-18},
	journal = {arXiv:1509.02897 [cs]},
	author = {Andoni, Alexandr and Indyk, Piotr and Laarhoven, Thijs and Razenshteyn, Ilya and Schmidt, Ludwig},
	month = sep,
	year = {2015},
	note = {arXiv: 1509.02897},
	keywords = {Computer Science - Computational Geometry, Computer Science - Data Structures and Algorithms, Computer Science - Information Retrieval},
	file = {Andoni et al. - 2015 - Practical and Optimal LSH for Angular Distance.pdf:C\:\\Users\\ituki\\Zotero\\storage\\CGUIGD27\\Andoni et al. - 2015 - Practical and Optimal LSH for Angular Distance.pdf:application/pdf},
}

@article{choi_dissertation_nodate,
	title = {A {Dissertation} {Presented} to {The} {Academic} {Faculty}},
	%%language = {en},
	journal = {ELECTRONIC HEALTH RECORDS},
	author = {Choi, Edward},
	pages = {155},
	file = {Choi - A Dissertation Presented to The Academic Faculty.pdf:C\:\\Users\\ituki\\Zotero\\storage\\47VYM6JS\\Choi - A Dissertation Presented to The Academic Faculty.pdf:application/pdf;Choi - A Dissertation Presented to The Academic Faculty.pdf:C\:\\Users\\ituki\\Zotero\\storage\\ZG2SS35U\\Choi - A Dissertation Presented to The Academic Faculty.pdf:application/pdf},
}

@article{peng_cm-gans_2018,
	title = {{CM}-{GANs}: {Cross}-modal {Generative} {Adversarial} {Networks} for {Common} {Representation} {Learning}},
	shorttitle = {{CM}-{GANs}},
	url = {http://arxiv.org/abs/1710.05106},
	abstract = {It is known that the inconsistent distribution and representation of different modalities, such as image and text, cause the heterogeneity gap, which makes it very challenging to correlate such heterogeneous data. Recently, generative adversarial networks (GANs) have been proposed and shown its strong ability of modeling data distribution and learning discriminative representation, and most of the existing GANs-based works mainly focus on the unidirectional generative problem to generate new data such as image synthesis. While we have completely different goal, which aims to effectively correlate existing largescale heterogeneous data of different modalities, by utilizing the power of GANs to model the cross-modal joint distribution. Thus, in this paper we propose Cross-modal Generative Adversarial Networks (CM-GANs) to learn discriminative common representation for bridging the heterogeneity gap. The main contributions can be summarized as follows: (1) Cross-modal GANs architecture is proposed to model the joint distribution over the data of different modalities. The inter-modality and intramodality correlation can be explored simultaneously in generative and discriminative models. Both of them beat each other to promote cross-modal correlation learning. (2) Cross-modal convolutional autoencoders with weight-sharing constraint are proposed to form the generative model. They can not only exploit the cross-modal correlation for learning the common representation, but also preserve the reconstruction information for capturing the semantic consistency within each modality. (3) Cross-modal adversarial mechanism is proposed, which utilizes two kinds of discriminative models to simultaneously conduct intra-modality and inter-modality discrimination. They can mutually boost to make the generated common representation more discriminative by adversarial training process. To the best of our knowledge, our proposed CM-GANs approach is the ﬁrst to utilize GANs to perform cross-modal common representation learning, by which the heterogeneous data can be effectively correlated. Extensive experiments are conducted to verify the performance of our proposed approach on cross-modal retrieval paradigm, compared with 10 state-of-the-art methods on 3 cross-modal datasets.},
	%%language = {en},
	%%%%%urldate = {2021-03-02},
	journal = {arXiv:1710.05106 [cs]},
	author = {Peng, Yuxin and Qi, Jinwei and Yuan, Yuxin},
	month = apr,
	year = {2018},
	note = {arXiv: 1710.05106},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Multimedia},
	file = {Peng et al. - 2018 - CM-GANs Cross-modal Generative Adversarial Networ.pdf:C\:\\Users\\ituki\\Zotero\\storage\\Y9YUH5KS\\Peng et al. - 2018 - CM-GANs Cross-modal Generative Adversarial Networ.pdf:application/pdf;Peng and Qi - 2019 - CM-GANs Cross-modal Generative Adversarial Networ.pdf:C\:\\Users\\ituki\\Zotero\\storage\\Z8T7M6EP\\Peng and Qi - 2019 - CM-GANs Cross-modal Generative Adversarial Networ.pdf:application/pdf},
}

@article{ruvolo_ella_nodate,
	title = {{ELLA}: {An} {Efficient} {Lifelong} {Learning} {Algorithm}},
	abstract = {The problem of learning multiple consecutive tasks, known as lifelong learning, is of great importance to the creation of intelligent, general-purpose, and ﬂexible machines. In this paper, we develop a method for online multi-task learning in the lifelong learning setting. The proposed Eﬃcient Lifelong Learning Algorithm (ELLA) maintains a sparsely shared basis for all task models, transfers knowledge from the basis to learn each new task, and reﬁnes the basis over time to maximize performance across all tasks. We show that ELLA has strong connections to both online dictionary learning for sparse coding and state-of-the-art batch multi-task learning methods, and provide robust theoretical performance guarantees. We show empirically that ELLA yields nearly identical performance to batch multi-task learning while learning tasks sequentially in three orders of magnitude (over 1,000x) less time.},
	%%language = {en},
	author = {Ruvolo, Paul and Eaton, Eric},
	pages = {9},
	file = {Ruvolo and Eaton - ELLA An Efficient Lifelong Learning Algorithm.pdf:C\:\\Users\\ituki\\Zotero\\storage\\M4I28DJD\\Ruvolo and Eaton - ELLA An Efficient Lifelong Learning Algorithm.pdf:application/pdf;Ruvolo and Eaton - ELLA An Efficient Lifelong Learning Algorithm.pdf:C\:\\Users\\ituki\\Zotero\\storage\\FLDCQ7E7\\Ruvolo and Eaton - ELLA An Efficient Lifelong Learning Algorithm.pdf:application/pdf},
}

@article{choi_generating_2018,
	title = {Generating {Multi}-label {Discrete} {Patient} {Records} using {Generative} {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1703.06490},
	abstract = {Access to electronic health record (EHR) data has motivated computational advances in medical research. However, various concerns, particularly over privacy, can limit access to and collaborative use of EHR data. Sharing synthetic EHR data could mitigate risk.},
	%%language = {en},
	%%%%%urldate = {2021-03-02},
	journal = {arXiv:1703.06490 [cs]},
	author = {Choi, Edward and Biswal, Siddharth and Malin, Bradley and Duke, Jon and Stewart, Walter F. and Sun, Jimeng},
	month = jan,
	year = {2018},
	note = {arXiv: 1703.06490},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {Choi et al. - 2018 - Generating Multi-label Discrete Patient Records us.pdf:C\:\\Users\\ituki\\Zotero\\storage\\CU6I7BYE\\Choi et al. - 2018 - Generating Multi-label Discrete Patient Records us.pdf:application/pdf;Choi et al. - Generating Multi-label Discrete Patient Records us.pdf:C\:\\Users\\ituki\\Zotero\\storage\\EBJ5PUEU\\Choi et al. - Generating Multi-label Discrete Patient Records us.pdf:application/pdf},
}

@article{jianchao_yang_image_2010,
	title = {Image {Super}-{Resolution} {Via} {Sparse} {Representation}},
	volume = {19},
	issn = {1057-7149},
	url = {http://ieeexplore.ieee.org/document/5466111/},
	doi = {10.1109/TIP.2010.2050625},
	abstract = {This paper presents a new approach to single-image superresolution, based on sparse signal representation. Research on image statistics suggests that image patches can be wellrepresented as a sparse linear combination of elements from an appropriately chosen over-complete dictionary. Inspired by this observation, we seek a sparse representation for each patch of the low-resolution input, and then use the coefﬁcients of this representation to generate the high-resolution output. Theoretical results from compressed sensing suggest that under mild conditions, the sparse representation can be correctly recovered from the downsampled signals. By jointly training two dictionaries for the low- and high-resolution image patches, we can enforce the similarity of sparse representations between the low resolution and high resolution image patch pair with respect to their own dictionaries. Therefore, the sparse representation of a low resolution image patch can be applied with the high resolution image patch dictionary to generate a high resolution image patch. The learned dictionary pair is a more compact representation of the patch pairs, compared to previous approaches, which simply sample a large amount of image patch pairs [1], reducing the computational cost substantially. The effectiveness of such a sparsity prior is demonstrated for both general image superresolution and the special case of face hallucination. In both cases, our algorithm generates high-resolution images that are competitive or even superior in quality to images produced by other similar SR methods. In addition, the local sparse modeling of our approach is naturally robust to noise, and therefore the proposed algorithm can handle super-resolution with noisy inputs in a more uniﬁed framework.},
	%%language = {en},
	number = {11},
	%%%%%urldate = {2021-03-02},
	journal = {IEEE Transactions on Image Processing},
	author = {{Jianchao Yang} and Wright, John and Huang, Thomas S and {Yi Ma}},
	month = nov,
	year = {2010},
	pages = {2861--2873},
	file = {Jianchao Yang et al. - 2010 - Image Super-Resolution Via Sparse Representation.pdf:C\:\\Users\\ituki\\Zotero\\storage\\ICKHHMLC\\Jianchao Yang et al. - 2010 - Image Super-Resolution Via Sparse Representation.pdf:application/pdf;Jianchao Yang et al. - 2010 - Image Super-Resolution Via Sparse Representation.pdf:C\:\\Users\\ituki\\Zotero\\storage\\6RERC73G\\Jianchao Yang et al. - 2010 - Image Super-Resolution Via Sparse Representation.pdf:application/pdf},
}

@article{chen_infogan_2016,
	title = {{InfoGAN}: {Interpretable} {Representation} {Learning} by {Information} {Maximizing} {Generative} {Adversarial} {Nets}},
	shorttitle = {{InfoGAN}},
	url = {http://arxiv.org/abs/1606.03657},
	abstract = {This paper describes InfoGAN, an information-theoretic extension to the Generative Adversarial Network that is able to learn disentangled representations in a completely unsupervised manner. InfoGAN is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation. We derive a lower bound of the mutual information objective that can be optimized efﬁciently. Speciﬁcally, InfoGAN successfully disentangles writing styles from digit shapes on the MNIST dataset, pose from lighting of 3D rendered images, and background digits from the central digit on the SVHN dataset. It also discovers visual concepts that include hair styles, presence/absence of eyeglasses, and emotions on the CelebA face dataset. Experiments show that InfoGAN learns interpretable representations that are competitive with representations learned by existing supervised methods.},
	%%language = {en},
	%%%%%urldate = {2021-03-02},
	journal = {arXiv:1606.03657 [cs, stat]},
	author = {Chen, Xi and Duan, Yan and Houthooft, Rein and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
	month = jun,
	year = {2016},
	note = {arXiv: 1606.03657},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Chen et al. - 2016 - InfoGAN Interpretable Representation Learning by .pdf:C\:\\Users\\ituki\\Zotero\\storage\\BBMQRH9K\\Chen et al. - 2016 - InfoGAN Interpretable Representation Learning by .pdf:application/pdf;Chen et al. - InfoGAN Interpretable Representation Learning by .pdf:C\:\\Users\\ituki\\Zotero\\storage\\V6S6ULL7\\Chen et al. - InfoGAN Interpretable Representation Learning by .pdf:application/pdf},
}

@article{ji_invariant_2019,
	title = {Invariant {Information} {Clustering} for {Unsupervised} {Image} {Classification} and {Segmentation}},
	url = {http://arxiv.org/abs/1807.06653},
	abstract = {We present a novel clustering objective that learns a neural network classifier from scratch, given only unlabelled data samples. The model discovers clusters that accurately match semantic classes, achieving state-of-the-art results in eight unsupervised clustering benchmarks spanning image classification and segmentation. These include STL10, an unsupervised variant of ImageNet, and CIFAR10, where we significantly beat the accuracy of our closest competitors by 6.6 and 9.5 absolute percentage points respectively. The method is not specialised to computer vision and operates on any paired dataset samples; in our experiments we use random transforms to obtain a pair from each image. The trained network directly outputs semantic labels, rather than high dimensional representations that need external processing to be usable for semantic clustering. The objective is simply to maximise mutual information between the class assignments of each pair. It is easy to implement and rigorously grounded in information theory, meaning we effortlessly avoid degenerate solutions that other clustering methods are susceptible to. In addition to the fully unsupervised mode, we also test two semi-supervised settings. The first achieves 88.8\% accuracy on STL10 classification, setting a new global state-of-the-art over all existing methods (whether supervised, semi-supervised or unsupervised). The second shows robustness to 90\% reductions in label coverage, of relevance to applications that wish to make use of small amounts of labels. github.com/xu-ji/IIC},
	%%language = {en},
	%%%%%urldate = {2021-03-02},
	journal = {arXiv:1807.06653 [cs]},
	author = {Ji, Xu and Henriques, João F. and Vedaldi, Andrea},
	month = aug,
	year = {2019},
	note = {arXiv: 1807.06653},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {Ji et al. - 2019 - Invariant Information Clustering for Unsupervised .pdf:C\:\\Users\\ituki\\Zotero\\storage\\5AYUPFCX\\Ji et al. - 2019 - Invariant Information Clustering for Unsupervised .pdf:application/pdf},
}

@incollection{leibe_perceptual_2016,
	address = {Cham},
	title = {Perceptual {Losses} for {Real}-{Time} {Style} {Transfer} and {Super}-{Resolution}},
	volume = {9906},
	isbn = {978-3-319-46474-9 978-3-319-46475-6},
	url = {http://link.springer.com/10.1007/978-3-319-46475-6_43},
	abstract = {We consider image transformation problems, where an input image is transformed into an output image. Recent methods for such problems typically train feed-forward convolutional neural networks using a per-pixel loss between the output and ground-truth images. Parallel work has shown that high-quality images can be generated by deﬁning and optimizing perceptual loss functions based on high-level features extracted from pretrained networks. We combine the beneﬁts of both approaches, and propose the use of perceptual loss functions for training feed-forward networks for image transformation tasks. We show results on image style transfer, where a feed-forward network is trained to solve the optimization problem proposed by Gatys et al. in real-time. Compared to the optimization-based method, our network gives similar qualitative results but is three orders of magnitude faster. We also experiment with single-image super-resolution, where replacing a per-pixel loss with a perceptual loss gives visually pleasing results.},
	%%language = {en},
	%%%%%urldate = {2021-03-02},
	booktitle = {Computer {Vision} – {ECCV} 2016},
	publisher = {Springer International Publishing},
	author = {Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li},
	editor = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
	year = {2016},
	doi = {10.1007/978-3-319-46475-6_43},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {694--711},
	file = {Johnson et al. - 2016 - Perceptual Losses for Real-Time Style Transfer and.pdf:C\:\\Users\\ituki\\Zotero\\storage\\DXXDWEZH\\Johnson et al. - 2016 - Perceptual Losses for Real-Time Style Transfer and.pdf:application/pdf;Johnson et al. - 2016 - Perceptual Losses for Real-Time Style Transfer and.pdf:C\:\\Users\\ituki\\Zotero\\storage\\WYBN9QCZ\\Johnson et al. - 2016 - Perceptual Losses for Real-Time Style Transfer and.pdf:application/pdf},
}

@article{rostami_learning_nodate,
	title = {Learning {Transferable} {Knowledge} {Through} {Embedding} {Spaces}},
	%%language = {en},
	author = {Rostami, Mohammad},
	pages = {259},
	file = {Rostami - Learning Transferable Knowledge Through Embedding .pdf:C\:\\Users\\ituki\\Zotero\\storage\\5L5BU7CF\\Rostami - Learning Transferable Knowledge Through Embedding .pdf:application/pdf;Rostami - Learning Transferable Knowledge Through Embedding .pdf:C\:\\Users\\ituki\\Zotero\\storage\\BVZPGTD6\\Rostami - Learning Transferable Knowledge Through Embedding .pdf:application/pdf;SCGANs.pdf:C\:\\Users\\ituki\\Zotero\\storage\\9QCMPXCF\\SCGANs.pdf:application/pdf},
}

@article{tschannen_mutual_2020,
	title = {On {Mutual} {Information} {Maximization} for {Representation} {Learning}},
	url = {http://arxiv.org/abs/1907.13625},
	abstract = {Many recent methods for unsupervised or self-supervised representation learning train feature extractors by maximizing an estimate of the mutual information (MI) between different views of the data. This comes with several immediate problems: For example, MI is notoriously hard to estimate, and using it as an objective for representation learning may lead to highly entangled representations due to its invariance under arbitrary invertible transformations. Nevertheless, these methods have been repeatedly shown to excel in practice. In this paper we argue, and provide empirical evidence, that the success of these methods cannot be attributed to the properties of MI alone, and that they strongly depend on the inductive bias in both the choice of feature extractor architectures and the parametrization of the employed MI estimators. Finally, we establish a connection to deep metric learning and argue that this interpretation may be a plausible explanation for the success of the recently introduced methods.},
	%%language = {en},
	%%%%%urldate = {2021-03-02},
	journal = {arXiv:1907.13625 [cs, stat]},
	author = {Tschannen, Michael and Djolonga, Josip and Rubenstein, Paul K. and Gelly, Sylvain and Lucic, Mario},
	month = jan,
	year = {2020},
	note = {arXiv: 1907.13625},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Tschannen et al. - 2020 - On Mutual Information Maximization for Representat.pdf:C\:\\Users\\ituki\\Zotero\\storage\\C5YARGUS\\Tschannen et al. - 2020 - On Mutual Information Maximization for Representat.pdf:application/pdf},
}

@article{oord_representation_2019,
	title = {Representation {Learning} with {Contrastive} {Predictive} {Coding}},
	url = {http://arxiv.org/abs/1807.03748},
	abstract = {While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artiﬁcial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.},
	%%language = {en},
	%%%%urldate = {2021-03-02},
	journal = {arXiv:1807.03748 [cs, stat]},
	author = {Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
	month = jan,
	year = {2019},
	note = {arXiv: 1807.03748},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Oord et al. - 2019 - Representation Learning with Contrastive Predictiv.pdf:C\:\\Users\\ituki\\Zotero\\storage\\J64N5MWR\\Oord et al. - 2019 - Representation Learning with Contrastive Predictiv.pdf:application/pdf},
}

@article{smith_novel_nodate,
	title = {Novel {Estimation} {Methods} for {Unsupervised} {Discovery} of {Latent} {Structure} in {Natural} {Language} {Text}},
	%%language = {en},
	author = {Smith, Noah Ashton},
	pages = {228},
	file = {Smith - Novel Estimation Methods for Unsupervised Discover.pdf:C\:\\Users\\ituki\\Zotero\\storage\\XT9ZMHSP\\Smith - Novel Estimation Methods for Unsupervised Discover.pdf:application/pdf;Smith - Novel Estimation Methods for Unsupervised Discover.pdf:C\:\\Users\\ituki\\Zotero\\storage\\AK4KNGGB\\Smith - Novel Estimation Methods for Unsupervised Discover.pdf:application/pdf},
}

@article{miotto_deep_2016,
	title = {Deep {Patient}: {An} {Unsupervised} {Representation} to {Predict} the {Future} of {Patients} from the {Electronic} {Health} {Records}},
	volume = {6},
	issn = {2045-2322},
	shorttitle = {Deep {Patient}},
	url = {http://www.nature.com/articles/srep26094},
	doi = {10.1038/srep26094},
	%%language = {en},
	number = {1},
	%%%%urldate = {2021-03-02},
	journal = {Scientific Reports},
	author = {Miotto, Riccardo and Li, Li and Kidd, Brian A. and Dudley, Joel T.},
	month = may,
	year = {2016},
	pages = {26094},
	file = {Miotto et al. - 2016 - Deep Patient An Unsupervised Representation to Pr.pdf:C\:\\Users\\ituki\\Zotero\\storage\\QQXVPILH\\Miotto et al. - 2016 - Deep Patient An Unsupervised Representation to Pr.pdf:application/pdf;Miotto et al. - 2016 - Deep Patient An Unsupervised Representation to Pr.pdf:C\:\\Users\\ituki\\Zotero\\storage\\545RXGBH\\Miotto et al. - 2016 - Deep Patient An Unsupervised Representation to Pr.pdf:application/pdf},
}

@article{springenberg_striving_2015,
	title = {Striving for {Simplicity}: {The} {All} {Convolutional} {Net}},
	shorttitle = {Striving for {Simplicity}},
	url = {http://arxiv.org/abs/1412.6806},
	abstract = {Most modern convolutional neural networks (CNNs) used for object recognition are built using the same principles: Alternating convolution and max-pooling layers followed by a small number of fully connected layers. We re-evaluate the state of the art for object recognition from small images with convolutional networks, questioning the necessity of different components in the pipeline. We ﬁnd that max-pooling can simply be replaced by a convolutional layer with increased stride without loss in accuracy on several image recognition benchmarks. Following this ﬁnding – and building on other recent work for ﬁnding simple network structures – we propose a new architecture that consists solely of convolutional layers and yields competitive or state of the art performance on several object recognition datasets (CIFAR-10, CIFAR-100, ImageNet). To analyze the network we introduce a new variant of the “deconvolution approach” for visualizing features learned by CNNs, which can be applied to a broader range of network structures than existing approaches.},
	%%language = {en},
	%%%%urldate = {2021-03-02},
	journal = {arXiv:1412.6806 [cs]},
	author = {Springenberg, Jost Tobias and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, Martin},
	month = apr,
	year = {2015},
	note = {arXiv: 1412.6806},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {Springenberg et al. - 2015 - Striving for Simplicity The All Convolutional Net.pdf:C\:\\Users\\ituki\\Zotero\\storage\\RLGFNUNY\\Springenberg et al. - 2015 - Striving for Simplicity The All Convolutional Net.pdf:application/pdf;Springenberg et al. - 2015 - STRIVING FOR SIMPLICITY THE ALL CONVOLUTIONAL NET.pdf:C\:\\Users\\ituki\\Zotero\\storage\\IPCCFAKX\\Springenberg et al. - 2015 - STRIVING FOR SIMPLICITY THE ALL CONVOLUTIONAL NET.pdf:application/pdf},
}

@article{zhu_unpaired_2020,
	title = {Unpaired {Image}-to-{Image} {Translation} using {Cycle}-{Consistent} {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1703.10593},
	abstract = {Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain X to a target domain Y in the absence of paired examples. Our goal is to learn a mapping G : X → Y such that the distribution of images from G(X) is indistinguishable from the distribution Y using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping F : Y → X and introduce a cycle consistency loss to enforce F (G(X)) ≈ X (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transﬁguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach.},
	%%language = {en},
	%%%%urldate = {2021-03-02},
	journal = {arXiv:1703.10593 [cs]},
	author = {Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.},
	month = aug,
	year = {2020},
	note = {arXiv: 1703.10593},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Zhu et al. - 2020 - Unpaired Image-to-Image Translation using Cycle-Co.pdf:C\:\\Users\\ituki\\Zotero\\storage\\R3AP3XAB\\Zhu et al. - 2020 - Unpaired Image-to-Image Translation using Cycle-Co.pdf:application/pdf},
}

@article{radford_unsupervised_2016,
	title = {Unsupervised {Representation} {Learning} with {Deep} {Convolutional} {Generative} {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1511.06434},
	abstract = {In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.},
	%%language = {en},
	%%%%urldate = {2021-03-02},
	journal = {arXiv:1511.06434 [cs]},
	author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
	month = jan,
	year = {2016},
	note = {arXiv: 1511.06434},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {Radford et al. - 2016 - Unsupervised Representation Learning with Deep Con.pdf:C\:\\Users\\ituki\\Zotero\\storage\\WUBEAUXR\\Radford et al. - 2016 - Unsupervised Representation Learning with Deep Con.pdf:application/pdf;Radford et al. - 2016 - UNSUPERVISED REPRESENTATION LEARNING WITH DEEP CON.pdf:C\:\\Users\\ituki\\Zotero\\storage\\I2DH7LAW\\Radford et al. - 2016 - UNSUPERVISED REPRESENTATION LEARNING WITH DEEP CON.pdf:application/pdf},
}

@article{noauthor_belmont_nodate,
	title = {The {Belmont} {Report}},
	abstract = {On July 12, 1974, the National Research Act (Pub. L. 93-348) was signed into law, there-by creating the National Commission for the Protection of Human Subjects of Biomedical and Behavioral Research. One of the charges to the Commission was to identify the basic ethical principles that should underlie the conduct of biomedical and behavioral research involving human subjects and to develop guidelines which should be followed to assure that such research is conducted in accordance with those principles. In carrying out the above, the Commission was directed to consider: (i) the boundaries between biomedical and behavioral research and the accepted and routine practice of medicine, (ii) the role of assessment of risk-benefit criteria in the determination of the appropriateness of research involving human subjects, (iii) appropriate guidelines for the selection of human subjects for participation in such research and (iv) the nature and definition of informed consent in various research settings.},
	%language = {en},
	pages = {10},
	file = {The Belmont Report.pdf:C\:\\Users\\ituki\\Zotero\\storage\\A7LF6GAA\\The Belmont Report.pdf:application/pdf;The Belmont Report.pdf:C\:\\Users\\ituki\\Zotero\\storage\\K6LHFZXQ\\The Belmont Report.pdf:application/pdf},
}

@article{makhzani_adversarial_2016,
	title = {Adversarial {Autoencoders}},
	url = {http://arxiv.org/abs/1511.05644},
	abstract = {In this paper, we propose the “adversarial autoencoder” (AAE), which is a probabilistic autoencoder that uses the recently proposed generative adversarial networks (GAN) to perform variational inference by matching the aggregated posterior of the hidden code vector of the autoencoder with an arbitrary prior distribution. Matching the aggregated posterior to the prior ensures that generating from any part of prior space results in meaningful samples. As a result, the decoder of the adversarial autoencoder learns a deep generative model that maps the imposed prior to the data distribution. We show how the adversarial autoencoder can be used in applications such as semi-supervised classiﬁcation, disentangling style and content of images, unsupervised clustering, dimensionality reduction and data visualization. We performed experiments on MNIST, Street View House Numbers and Toronto Face datasets and show that adversarial autoencoders achieve competitive results in generative modeling and semi-supervised classiﬁcation tasks.},
	%language = {en},
	%%%%urldate = {2021-03-02},
	journal = {arXiv:1511.05644 [cs]},
	author = {Makhzani, Alireza and Shlens, Jonathon and Jaitly, Navdeep and Goodfellow, Ian and Frey, Brendan},
	month = may,
	year = {2016},
	note = {arXiv: 1511.05644},
	keywords = {Computer Science - Machine Learning},
	file = {Makhzani et al. - 2016 - Adversarial Autoencoders.pdf:C\:\\Users\\ituki\\Zotero\\storage\\5VZAPP3X\\Makhzani et al. - 2016 - Adversarial Autoencoders.pdf:application/pdf},
}

@article{kingma_auto-encoding_2014,
	title = {Auto-{Encoding} {Variational} {Bayes}},
	url = {http://arxiv.org/abs/1312.6114},
	abstract = {How can we perform efﬁcient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efﬁcient by ﬁtting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reﬂected in experimental results.},
	%language = {en},
	%%%%urldate = {2021-03-02},
	journal = {arXiv:1312.6114 [cs, stat]},
	author = {Kingma, Diederik P. and Welling, Max},
	month = may,
	year = {2014},
	note = {arXiv: 1312.6114},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Kingma and Welling - 2014 - Auto-Encoding Variational Bayes.pdf:C\:\\Users\\ituki\\Zotero\\storage\\LS4PC5QX\\Kingma and Welling - 2014 - Auto-Encoding Variational Bayes.pdf:application/pdf},
}

@article{higgins_-vae_2017,
	title = {β-{VAE}: {Learning} {Basic} {Visual} {Concepts} {With} {A} {Constrained} {Variational} {Frameworks}},
	abstract = {Learning an interpretable factorised representation of the independent data generative factors of the world without supervision is an important precursor for the development of artiﬁcial intelligence that is able to learn and reason in the same way that humans do. We introduce β-VAE, a new state-of-the-art framework for automated discovery of interpretable factorised latent representations from raw image data in a completely unsupervised manner. Our approach is a modiﬁcation of the variational autoencoder (VAE) framework. We introduce an adjustable hyperparameter β that balances latent channel capacity and independence constraints with reconstruction accuracy. We demonstrate that β-VAE with appropriately tuned β {\textgreater} 1 qualitatively outperforms VAE (β = 1), as well as state of the art unsupervised (InfoGAN) and semi-supervised (DC-IGN) approaches to disentangled factor learning on a variety of datasets (celebA, faces and chairs). Furthermore, we devise a protocol to quantitatively compare the degree of disentanglement learnt by different models, and show that our approach also signiﬁcantly outperforms all baselines quantitatively. Unlike InfoGAN, β-VAE is stable to train, makes few assumptions about the data and relies on tuning a single hyperparameter β, which can be directly optimised through a hyperparameter search using weakly labelled data or through heuristic visual inspection for purely unsupervised data.},
	%language = {en},
	author = {Higgins, Irina and Matthey, Loic and Pal, Arka and Burgess, Christopher and Glorot, Xavier and Botvinick, Matthew and Mohamed, Shakir and Lerchner, Alexander},
	year = {2017},
	pages = {22},
	file = {Higgins et al. - 2017 - β-VAE LEARNING BASIC VISUAL CONCEPTS WITH A CONST.pdf:C\:\\Users\\ituki\\Zotero\\storage\\85I4SBCR\\Higgins et al. - 2017 - β-VAE LEARNING BASIC VISUAL CONCEPTS WITH A CONST.pdf:application/pdf;Higgins et al. - 2017 - β-VAE LEARNING BASIC VISUAL CONCEPTS WITH A CONST.pdf:C\:\\Users\\ituki\\Zotero\\storage\\U29BMLLT\\Higgins et al. - 2017 - β-VAE LEARNING BASIC VISUAL CONCEPTS WITH A CONST.pdf:application/pdf},
}

@article{locatello_challenging_2019,
	title = {Challenging {Common} {Assumptions} in the {Unsupervised} {Learning} of {Disentangled} {Representations}},
	url = {http://arxiv.org/abs/1811.12359},
	abstract = {The key idea behind the unsupervised learning of disentangled representations is that real-world data is generated by a few explanatory factors of variation which can be recovered by unsupervised learning algorithms. In this paper, we provide a sober look at recent progress in the ﬁeld and challenge some common assumptions. We ﬁrst theoretically show that the unsupervised learning of disentangled representations is fundamentally impossible without inductive biases on both the models and the data. Then, we train more than 12 000 models covering most prominent methods and evaluation metrics in a reproducible large-scale experimental study on seven different data sets. We observe that while the different methods successfully enforce properties “encouraged” by the corresponding losses, well-disentangled models seemingly cannot be identiﬁed without supervision. Furthermore, increased disentanglement does not seem to lead to a decreased sample complexity of learning for downstream tasks. Our results suggest that future work on disentanglement learning should be explicit about the role of inductive biases and (implicit) supervision, investigate concrete beneﬁts of enforcing disentanglement of the learned representations, and consider a reproducible experimental setup covering several data sets.},
	%language = {en},
	%%%%urldate = {2021-03-02},
	journal = {arXiv:1811.12359 [cs, stat]},
	author = {Locatello, Francesco and Bauer, Stefan and Lucic, Mario and Rätsch, Gunnar and Gelly, Sylvain and Schölkopf, Bernhard and Bachem, Olivier},
	month = jun,
	year = {2019},
	note = {arXiv: 1811.12359},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Locatello et al. - 2019 - Challenging Common Assumptions in the Unsupervised.pdf:C\:\\Users\\ituki\\Zotero\\storage\\E24JHS2R\\Locatello et al. - 2019 - Challenging Common Assumptions in the Unsupervised.pdf:application/pdf;Locatello et al. - Challenging Common Assumptions in the Unsupervised.pdf:C\:\\Users\\ituki\\Zotero\\storage\\VA6VBF6T\\Locatello et al. - Challenging Common Assumptions in the Unsupervised.pdf:application/pdf},
}

@article{bengio_representation_2014,
	title = {Representation {Learning}: {A} {Review} and {New} {Perspectives}},
	shorttitle = {Representation {Learning}},
	url = {http://arxiv.org/abs/1206.5538},
	abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, auto-encoders, manifold learning, and deep networks. This motivates longer-term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation and manifold learning.},
	%language = {en},
	%%%%urldate = {2021-03-06},
	journal = {arXiv:1206.5538 [cs]},
	author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
	month = apr,
	year = {2014},
	note = {arXiv: 1206.5538},
	keywords = {Computer Science - Machine Learning},
	file = {Bengio et al. - 2014 - Representation Learning A Review and New Perspect.pdf:C\:\\Users\\ituki\\Zotero\\storage\\JNSYYJBP\\Bengio et al. - 2014 - Representation Learning A Review and New Perspect.pdf:application/pdf;Bengio et al. - 2013 - Representation Learning A Review and New Perspect.pdf:C\:\\Users\\ituki\\Zotero\\storage\\6ZQ8IZMK\\Bengio et al. - 2013 - Representation Learning A Review and New Perspect.pdf:application/pdf},
}

@inproceedings{ji_invariant_2019-1,
	address = {Seoul, Korea (South)},
	title = {Invariant {Information} {Clustering} for {Unsupervised} {Image} {Classification} and {Segmentation}},
	isbn = {978-1-72814-803-8},
	url = {https://ieeexplore.ieee.org/document/9008122/},
	doi = {10.1109/ICCV.2019.00996},
	%language = {en},
	%%%%urldate = {2021-03-06},
	booktitle = {2019 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	publisher = {IEEE},
	author = {Ji, Xu and Vedaldi, Andrea and Henriques, Joao},
	month = oct,
	year = {2019},
	pages = {9864--9873},
	file = {Ji et al. - 2019 - Invariant Information Clustering for Unsupervised .pdf:C\:\\Users\\ituki\\Zotero\\storage\\F5NTVESG\\Ji et al. - 2019 - Invariant Information Clustering for Unsupervised .pdf:application/pdf;Rifai11aCAE.pdf:C\:\\Users\\ituki\\Zotero\\storage\\6BZFCLHG\\Rifai11aCAE.pdf:application/pdf;vincent10a.pdf:C\:\\Users\\ituki\\Zotero\\storage\\CIPSC3WP\\vincent10a.pdf:application/pdf;Self-Supervised GANs via Auxiliary Rotation Loss.pdf:C\:\\Users\\ituki\\Zotero\\storage\\4H6JNX2A\\Self-Supervised GANs via Auxiliary Rotation Loss.pdf:application/pdf;NIPS-2011-the-manifold-tangent-classifier-Paper.pdf:C\:\\Users\\ituki\\Zotero\\storage\\VVC7BDBU\\NIPS-2011-the-manifold-tangent-classifier-Paper.pdf:application/pdf},
}

@article{tschannen_mutual_2020-1,
	title = {{ON} {MUTUAL} {INFORMATION} {MAXIMIZATION} {FOR} {REP}- {RESENTATION} {LEARNING}},
	abstract = {Many recent methods for unsupervised or self-supervised representation learning train feature extractors by maximizing an estimate of the mutual information (MI) between different views of the data. This comes with several immediate problems: For example, MI is notoriously hard to estimate, and using it as an objective for representation learning may lead to highly entangled representations due to its invariance under arbitrary invertible transformations. Nevertheless, these methods have been repeatedly shown to excel in practice. In this paper we argue, and provide empirical evidence, that the success of these methods cannot be attributed to the properties of MI alone, and that they strongly depend on the inductive bias in both the choice of feature extractor architectures and the parametrization of the employed MI estimators. Finally, we establish a connection to deep metric learning and argue that this interpretation may be a plausible explanation for the success of the recently introduced methods.},
	%%language = {en},
	author = {Tschannen, Michael and Djolonga, Josip and Rubenstein, Paul K and Gelly, Sylvain and Lucic, Mario},
	year = {2020},
	pages = {16},
	file = {Tschannen et al. - 2020 - ON MUTUAL INFORMATION MAXIMIZATION FOR REP- RESENT.pdf:C\:\\Users\\ituki\\Zotero\\storage\\H2ZHZZUT\\Tschannen et al. - 2020 - ON MUTUAL INFORMATION MAXIMIZATION FOR REP- RESENT.pdf:application/pdf},
}

@inproceedings{zhu_unpaired_2017,
	address = {Venice},
	title = {Unpaired {Image}-to-{Image} {Translation} {Using} {Cycle}-{Consistent} {Adversarial} {Networks}},
	isbn = {978-1-5386-1032-9},
	url = {http://ieeexplore.ieee.org/document/8237506/},
	doi = {10.1109/ICCV.2017.244},
	abstract = {Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain X to a target domain Y in the absence of paired examples. Our goal is to learn a mapping G : X → Y such that the distribution of images from G(X) is indistinguishable from the distribution Y using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping F : Y → X and introduce a cycle consistency loss to enforce F (G(X)) ≈ X (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transﬁguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach.},
	%%language = {en},
	%%%%urldate = {2021-03-06},
	booktitle = {2017 {IEEE} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	publisher = {IEEE},
	author = {Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.},
	month = oct,
	year = {2017},
	pages = {2242--2251},
	file = {Zhu et al. - 2017 - Unpaired Image-to-Image Translation Using Cycle-Co.pdf:C\:\\Users\\ituki\\Zotero\\storage\\JTIMTFZY\\Zhu et al. - 2017 - Unpaired Image-to-Image Translation Using Cycle-Co.pdf:application/pdf},
}

@article{mirza_conditional_nodate,
	title = {Conditional {Generative} {Adversarial} {Nets}},
	abstract = {Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.},
	%%language = {en},
	author = {Mirza, Mehdi and Osindero, Simon},
	year = {2016},
	pages = {7},
	file = {Mirza and Osindero - Conditional Generative Adversarial Nets.pdf:C\:\\Users\\ituki\\Zotero\\storage\\W393CHSD\\Mirza and Osindero - Conditional Generative Adversarial Nets.pdf:application/pdf},
}

@article{shu_weakly_2020,
	title = {{WEAKLY} {SUPERVISED} {DISENTANGLEMENT} {WITH} {GUARANTEES}},
	abstract = {Learning disentangled representations that correspond to factors of variation in real-world data is critical to interpretable and human-controllable machine learning. Recently, concerns about the viability of learning disentangled representations in a purely unsupervised manner has spurred a shift toward the incorporation of weak supervision. However, there is currently no formalism that identiﬁes when and how weak supervision will guarantee disentanglement. To address this issue, we provide a theoretical framework to assist in analyzing the disentanglement guarantees (or lack thereof) conferred by weak supervision when coupled with learning algorithms based on distribution matching. We empirically verify the guarantees and limitations of several weak supervision methods (restricted labeling, match-pairing, and rank-pairing), demonstrating the predictive power and usefulness of our theoretical framework.},
	%language = {en},
	author = {Shu, Rui and Chen, Yining and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
	year = {2020},
	pages = {36},
	file = {Shu et al. - 2020 - WEAKLY SUPERVISED DISENTANGLEMENT WITH GUARANTEES:C\:\\Users\\ituki\\Zotero\\storage\\VWNSZAUG\\Shu et al. - 2020 - WEAKLY SUPERVISED DISENTANGLEMENT WITH GUARANTEES:application/pdf},
}

@article{chen_self-supervised_2019,
	title = {Self-{Supervised} {GANs} via {Auxiliary} {Rotation} {Loss}},
	url = {http://arxiv.org/abs/1811.11212},
	abstract = {Conditional GANs are at the forefront of natural image synthesis. The main drawback of such models is the necessity for labeled data. In this work we exploit two popular unsupervised learning techniques, adversarial training and self-supervision, and take a step towards bridging the gap between conditional and unconditional GANs. In particular, we allow the networks to collaborate on the task of representation learning, while being adversarial with respect to the classic GAN game. The role of self-supervision is to encourage the discriminator to learn meaningful feature representations which are not forgotten during training. We test empirically both the quality of the learned image representations, and the quality of the synthesized images. Under the same conditions, the self-supervised GAN attains a similar performance to state-of-the-art conditional counterparts. Finally, we show that this approach to fully unsupervised learning can be scaled to attain an FID of 23.4 on unconditional ImageNet generation.},
	%%language = {en},
	%%%%urldate = {2021-03-07},
	journal = {arXiv:1811.11212 [cs, stat]},
	author = {Chen, Ting and Zhai, Xiaohua and Ritter, Marvin and Lucic, Mario and Houlsby, Neil},
	month = apr,
	year = {2019},
	note = {arXiv: 1811.11212},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Chen et al. - 2019 - Self-Supervised GANs via Auxiliary Rotation Loss.pdf:C\:\\Users\\ituki\\Zotero\\storage\\3DLQJM8V\\Chen et al. - 2019 - Self-Supervised GANs via Auxiliary Rotation Loss.pdf:application/pdf},
}


@article{chen_isolating_nodate,
	title = {Isolating {Sources} of {Disentanglement} in {VAEs}},
	abstract = {We decompose the evidence lower bound to show the existence of a term measuring the total correlation between latent variables. We use this to motivate the β-TCVAE (Total Correlation Variational Autoencoder) algorithm, a reﬁnement and plug-in replacement of the β-VAE for learning disentangled representations, requiring no additional hyperparameters during training. We further propose a principled classiﬁer-free measure of disentanglement called the mutual information gap (MIG). We perform extensive quantitative and qualitative experiments, in both restricted and non-restricted settings, and show a strong relation between total correlation and disentanglement, when the model is trained using our framework.},
	%%language = {en},
	author = {Chen, Ricky T Q and Li, Xuechen and Grosse, Roger and Duvenaud, David},
	pages = {11},
	file = {Chen et al. - Isolating Sources of Disentanglement in VAEs.pdf:C\:\\Users\\ituki\\Zotero\\storage\\XRDMJ3CF\\Chen et al. - Isolating Sources of Disentanglement in VAEs.pdf:application/pdf},
}

@article{vincent_stacked_nodate,
	title = {Stacked {Denoising} {Autoencoders}: {Learning} {Useful} {Representations} in a {Deep} {Network} with a {Local} {Denoising} {Criterion}},
	abstract = {We explore an original strategy for building deep networks, based on stacking layers of denoising autoencoders which are trained locally to denoise corrupted versions of their inputs. The resulting algorithm is a straightforward variation on the stacking of ordinary autoencoders. It is however shown on a benchmark of classiﬁcation problems to yield signiﬁcantly lower classiﬁcation error, thus bridging the performance gap with deep belief networks (DBN), and in several cases surpassing it. Higher level representations learnt in this purely unsupervised fashion also help boost the performance of subsequent SVM classiﬁers. Qualitative experiments show that, contrary to ordinary autoencoders, denoising autoencoders are able to learn Gabor-like edge detectors from natural image patches and larger stroke detectors from digit images. This work clearly establishes the value of using a denoising criterion as a tractable unsupervised objective to guide the learning of useful higher level representations.},
	%%language = {en},
	author = {Vincent, Pascal and Larochelle, Hugo and Lajoie, Isabelle and Bengio, Yoshua and Manzagol, Pierre-Antoine},
	pages = {38},
	year = {2010},
	file = {Vincent et al. - Stacked Denoising Autoencoders Learning Useful Re.pdf:C\:\\Users\\ituki\\Zotero\\storage\\DVET82QQ\\Vincent et al. - Stacked Denoising Autoencoders Learning Useful Re.pdf:application/pdf},
}

@article{rifai_contractive_nodate,
	title = {Contractive {Auto}-{Encoders}: {Explicit} {Invariance} {During} {Feature} {Extraction}},
	abstract = {We present in this paper a novel approach for training deterministic auto-encoders. We show that by adding a well chosen penalty term to the classical reconstruction cost function, we can achieve results that equal or surpass those attained by other regularized autoencoders as well as denoising auto-encoders on a range of datasets. This penalty term corresponds to the Frobenius norm of the Jacobian matrix of the encoder activations with respect to the input. We show that this penalty term results in a localized space contraction which in turn yields robust features on the activation layer. Furthermore, we show how this penalty term is related to both regularized auto-encoders and denoising auto-encoders and how it can be seen as a link between deterministic and non-deterministic auto-encoders. We ﬁnd empirically that this penalty helps to carve a representation that better captures the local directions of variation dictated by the data, corresponding to a lower-dimensional non-linear manifold, while being more invariant to the vast majority of directions orthogonal to the manifold. Finally, we show that by using the learned features to initialize a MLP, we achieve state of the art classiﬁcation error on a range of datasets, surpassing other methods of pretraining.},
	%%language = {en},
	author = {Rifai, Salah and Vincent, Pascal and Muller, Xavier and Glorot, Xavier and Bengio, Yoshua},
	pages = {8},
	year = {2011},
	file = {Rifai et al. - Contractive Auto-Encoders Explicit Invariance Dur.pdf:C\:\\Users\\ituki\\Zotero\\storage\\LJR7ASYR\\Rifai et al. - Contractive Auto-Encoders Explicit Invariance Dur.pdf:application/pdf},
}

@article{pratt_discriminability-based_nodate,
	title = {Discriminability-{Based} {Transfer} between {Neural} {Networks}},
	abstract = {Previously, we have introduced the idea of neural network transfer, where learning on a target problem is sped up by using the weights obtained from a network trained for a related source task. Here, we present a new algorithm. called Discriminability-Based Transfer (DBT), which uses an information measure to estimate the utility of hyperplanes defined by source weights in the target network, and rescales transferred weight magnitudes accordingly. Several experiments demonstrate that target networks initialized via DBT learn significantly faster than networks initialized randomly.},
	%%%language = {en},
	author = {Pratt, Lorien Y},
	pages = {8},
	file = {Pratt - Discriminability-Based Transfer between Neural Net.pdf:C\:\\Users\\ituki\\Zotero\\storage\\BQC9VJHU\\Pratt - Discriminability-Based Transfer between Neural Net.pdf:application/pdf},
}

@article{hupkes_compositionality_2020,
	title = {Compositionality {Decomposed}: {How} do {Neural} {Networks} {Generalise}?},
	volume = {67},
	issn = {1076-9757},
	shorttitle = {Compositionality {Decomposed}},
	url = {https://jair.org/index.php/jair/article/view/11674},
	doi = {10.1613/jair.1.11674},
	abstract = {Despite a multitude of empirical studies, little consensus exists on whether neural networks are able to generalise compositionally, a controversy that, in part, stems from a lack of agreement about what it means for a neural model to be compositional. As a response to this controversy, we present a set of tests that provide a bridge between, on the one hand, the vast amount of linguistic and philosophical theory about compositionality of language and, on the other, the successful neural models of language. We collect diﬀerent interpretations of compositionality and translate them into ﬁve theoretically grounded tests for models that are formulated on a task-independent level. In particular, we provide tests to investigate (i) if models systematically recombine known parts and rules (ii) if models can extend their predictions beyond the length they have seen in the training data (iii) if models’ composition operations are local or global (iv) if models’ predictions are robust to synonym substitutions and (v) if models favour rules or exceptions during training. To demonstrate the usefulness of this evaluation paradigm, we instantiate these ﬁve tests on a highly compositional data set which we dub PCFG SET and apply the resulting tests to three popular sequence-to-sequence models: a recurrent, a convolution-based and a transformer model. We provide an in-depth analysis of the results, which uncover the strengths and weaknesses of these three architectures and point to potential areas of improvement.},
	%language = {en},
	%%%%%%urldate = {2021-03-12},
	journal = {Journal of Artificial Intelligence Research},
	author = {Hupkes, Dieuwke and Dankers, Verna and Mul, Mathijs and Bruni, Elia},
	month = apr,
	year = {2020},
	pages = {757--795},
	file = {Hupkes et al. - 2020 - Compositionality Decomposed How do Neural Network.pdf:C\:\\Users\\ituki\\Zotero\\storage\\TFK2TYPG\\Hupkes et al. - 2020 - Compositionality Decomposed How do Neural Network.pdf:application/pdf},
}

@article{rifai_manifold_nodate,
	title = {The {Manifold} {Tangent} {Classifier}},
	abstract = {We combine three important ideas present in previous work for building classiﬁers: the semi-supervised hypothesis (the input distribution contains information about the classiﬁer), the unsupervised manifold hypothesis (data density concentrates near low-dimensional manifolds), and the manifold hypothesis for classiﬁcation (different classes correspond to disjoint manifolds separated by low density). We exploit a novel algorithm for capturing manifold structure (high-order contractive auto-encoders) and we show how it builds a topological atlas of charts, each chart being characterized by the principal singular vectors of the Jacobian of a representation mapping. This representation learning algorithm can be stacked to yield a deep architecture, and we combine it with a domain knowledge-free version of the TangentProp algorithm to encourage the classiﬁer to be insensitive to local directions changes along the manifold. Record-breaking classiﬁcation results are obtained.},
	%language = {en},
	author = {Rifai, Salah and Dauphin, Yann N and Vincent, Pascal and Bengio, Yoshua and Muller, Xavier},
	pages = {9},
	year = {2011},
	file = {Rifai et al. - The Manifold Tangent Classifier.pdf:C\:\\Users\\ituki\\Zotero\\storage\\R2G3ARHH\\Rifai et al. - The Manifold Tangent Classifier.pdf:application/pdf},
}
